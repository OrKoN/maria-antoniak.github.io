---
layout: default
---

# Machine Learning with Words: A Python Primer

This is a quick start primer to machine learning techniques for text data. You don't need any background in machine learning to follow this primer, but I'll assume that you know enough programming to understand my Python snippets.

My goal is to get you running a machine learning pipeline on your own dataset as quickly as possible. I want you to experience the magic of machine learning and start building cool things.

## Requirements

You will need Python 2.7 and the following Python packages:

* pandas
* scikit-learn
* gensim
* spaCy
* matplotlib
* seaborn

If you are new to Python (or feeling lazy), I recommend installing [Anaconda](https://www.continuum.io/anaconda-overview), which includes all of the above packages and is awesome.

I also recommend installing [PyCharm](https://www.jetbrains.com/pycharm/) to make debugging a bit easier. Alternately, you can use a [Jupyter notebook](http://jupyter.org/) to write and run your code (included with Anaconda). Jupyter notebooks are popular in data science and provide an interactive coding experience. You can even run them within PyCharm!

If you want to use Python 3, go for it! Just be aware that some of my code will need minor alterations to run.


## Find a dataset

You can use any text dataset you like. I'll be using a collection of Shakespeare plays from [Project Gutenberg](https://www.gutenberg.org/).

To make your first project easier, you might want to choose a dataset with the following qualities:

* machine-readable text (.txt or .csv files, not PDF)
* 1,000-100,000 documents
* a topic that is familiar to you


## Load and clean your dataset

Use **pandas** to load your data.

```python
import pandas as pd

pd.load_csv('/path/to/your/documents')
```

Clean the documents by removing numbers and punctuation, lowercasing the text, and removing words that occur fewer than N times.

{% highlight python %}
def remove_non_alpha(text):
    return re.sub('[^A-Za-z\s]', ' ', text)

def preprocess_text(text, stopwords=None):
    text = text.lower()
    text = remove_non_alpha(text)
    return text
{% endhighlight %}


## Create feature vectors.

A feature vector is a representation of a document that includes a list of **features** (words) and **values** (word frequencies). These vectors are how we communicate to the computer which aspects of the document are important. You could add extra features, such as the year or author, but for now, we'll just use words and their frequencies.

We'll use **scikit-learn** to create our feature vectors.

```python
vectorizer = TfidfVectorizer(norm='l2', use_idf=True, min_df=10, sublinear_tf=True)
vectorizer = vectorizer.fit(documents)
vectorizer.transform(documents)
```


## Cluster your dataset

**Clustering** means gathering documents into groups based on the similarity of their feature vectors.


```python
```



How it works: K-means searches for


## Discover topics in your dataset


## Label and classify your dataset


## Resources to learn more


<br>
